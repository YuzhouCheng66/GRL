{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a13004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yzcheng/anaconda3/envs/TorchGRL/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.5\n",
      "Counter({'num_full_filled': 8})\n",
      "done in:  1544\n",
      "Training Episode: 1 Reward: -649.0337086629082\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 1444), ('n_updates', 0), ('rlen', 1444)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.6\n",
      "Counter({'num_full_filled': 8})\n",
      "done in:  1734\n",
      "Training Episode: 2 Reward: -1022.3511106423498\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 3078), ('n_updates', 0), ('rlen', 3078)]\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 6})\n",
      "done in:  1429\n",
      "Training Episode: 3 Reward: -909.295167643892\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 4407), ('n_updates', 0), ('rlen', 4407)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "Counter({'num_full_filled': 6})\n",
      "done in:  2137\n",
      "Training Episode: 4 Reward: -801.8143310333884\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 6444), ('n_updates', 0), ('rlen', 6444)]\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.5\n",
      "Counter({'num_full_filled': 5})\n",
      "done in:  1782\n",
      "Training Episode: 5 Reward: -740.628494471585\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 8126), ('n_updates', 0), ('rlen', 8126)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.8\n",
      "Counter({'num_full_filled': 5})\n",
      "done in:  1639\n",
      "Training Episode: 6 Reward: -1010.8247765393414\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 9665), ('n_updates', 0), ('rlen', 9665)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.4\n",
      "Counter({'num_full_filled': 5})\n",
      "done in:  2079\n",
      "Training Episode: 7 Reward: -1133.2505014512712\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 11644), ('n_updates', 0), ('rlen', 11644)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "Training Episode: 8 Reward: -818.6112669017832\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 14144), ('n_updates', 0), ('rlen', 14144)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 7})\n",
      "done in:  1827\n",
      "Training Episode: 9 Reward: -634.0317066713442\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 15871), ('n_updates', 0), ('rlen', 15871)]\n"
     ]
    }
   ],
   "source": [
    "from flow.core.params import VehicleParams, InFlows, SumoCarFollowingParams, SumoParams, EnvParams, InitialConfig, \\\n",
    "    NetParams, SumoLaneChangeParams, TrafficLightParams\n",
    "from flow.controllers import IDMController, RLController\n",
    "from controller import SpecificMergeRouter\n",
    "from network import HighwayRampsNetwork, ADDITIONAL_NET_PARAMS\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "# ----------- Configurations -----------#\n",
    "TRAINING = True\n",
    "# TRAINING = False\n",
    "\n",
    "# TESTING = True\n",
    "TESTING = True\n",
    "\n",
    "# DEBUG = True\n",
    "DEBUG = False\n",
    "\n",
    "RENDER = True\n",
    "# RENDER = True\n",
    "\n",
    "NUM_HUMAN = 20\n",
    "actual_num_human = 10\n",
    "\n",
    "NUM_MERGE_0 = 10\n",
    "NUM_MERGE_1 = 10\n",
    "\n",
    "MAX_AV_SPEED = 14\n",
    "MAX_HV_SPEED = 10\n",
    "\n",
    "VEH_COLORS = ['blue', 'blue']\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\n",
    "Router = SpecificMergeRouter\n",
    "\n",
    "vehicles = VehicleParams()\n",
    "vehicles.add(veh_id=\"human\",\n",
    "             lane_change_params=SumoLaneChangeParams('only_strategic_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='right_of_way', min_gap=5, tau=1,\n",
    "                                                         max_speed=MAX_HV_SPEED),\n",
    "             acceleration_controller=(IDMController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             )\n",
    "\n",
    "vehicles.add(veh_id=\"merge_0\",\n",
    "             lane_change_params=SumoLaneChangeParams('no_cooperative_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='no_collide', min_gap=1, tau=1,\n",
    "                                                         max_speed=MAX_AV_SPEED),\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             color=VEH_COLORS[0])\n",
    "\n",
    "vehicles.add(veh_id=\"merge_1\",\n",
    "             lane_change_params=SumoLaneChangeParams('no_cooperative_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='no_collide', min_gap=1, tau=1,\n",
    "                                                         max_speed=MAX_AV_SPEED),\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             color=VEH_COLORS[1])\n",
    "\n",
    "initial_config = InitialConfig(spacing='uniform')\n",
    "\n",
    "inflow = InFlows()\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "obstacle = {\"departPos\": np.random.randint(100, 101),\n",
    "            \"arrivalPos\": 200, \n",
    "            \"arrivalEdge\":0,  \n",
    "            \"speedFactor\":0.00001, \n",
    "            \"color\":\"red\"}\n",
    "\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           period=100000,\n",
    "           depart_lane=0,\n",
    "           depart_speed=0,\n",
    "           route='routehighway_0_0',\n",
    "           number=1,\n",
    "           **obstacle)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane=1,\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=int(actual_num_human/2))\n",
    "\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane=2,\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=int(actual_num_human/2))\n",
    "\n",
    "inflow.add(veh_type=\"merge_0\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane='random',\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=NUM_MERGE_0)\n",
    "\n",
    "inflow.add(veh_type=\"merge_1\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane='random',\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=NUM_MERGE_1)\n",
    "\n",
    "sim_params = SumoParams(sim_step=0.1, restart_instance=True, render=RENDER, save_render=False)\n",
    "\n",
    "from specific_environment import MergeEnv\n",
    "\n",
    "intention_dic = {\"human\": 0, \"merge_0\": 1, \"merge_1\": 2}\n",
    "terminal_edges = ['off_ramp_0', 'off_ramp_1', 'highway_2']\n",
    "\n",
    "env_params = EnvParams(warmup_steps=100,\n",
    "                       additional_params={\"intention\": intention_dic,\n",
    "                                          \"max_av_speed\": MAX_AV_SPEED,\n",
    "                                          \"max_hv_speed\": MAX_HV_SPEED})\n",
    "\n",
    "additional_net_params = ADDITIONAL_NET_PARAMS.copy()\n",
    "additional_net_params['num_vehicles'] = NUM_HUMAN + NUM_MERGE_0 + NUM_MERGE_1\n",
    "additional_net_params['num_cav'] = NUM_MERGE_0 + NUM_MERGE_1\n",
    "additional_net_params['num_hv'] = NUM_HUMAN\n",
    "additional_net_params['terminal_edges'] = terminal_edges\n",
    "\n",
    "net_params = NetParams(inflows=inflow, additional_params=additional_net_params)\n",
    "\n",
    "traffic_lights = TrafficLightParams()\n",
    "\n",
    "network = HighwayRampsNetwork(\"highway_ramp\", vehicles, net_params, initial_config, traffic_lights)\n",
    "\n",
    "\n",
    "# ----------- Model Building -----------#\n",
    "flow_params = dict(\n",
    "    exp_tag='test_network',\n",
    "    env_name=MergeEnv,\n",
    "    network=network,\n",
    "    simulator='traci',\n",
    "    sim=sim_params,\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,\n",
    "    initial=initial_config,\n",
    "    tls=traffic_lights\n",
    ")\n",
    "\n",
    "# number of time steps\n",
    "flow_params['env'].horizon = 2500\n",
    "\n",
    "\n",
    "from Experiment.DQN_experiments import Experiment\n",
    "\n",
    "exp = Experiment(flow_params)\n",
    "\n",
    "\n",
    "# run the sumo simulation\n",
    "exp.run(num_runs=1, training=TRAINING,\n",
    "        testing=TESTING,\n",
    "        num_human=NUM_HUMAN,\n",
    "        actual_num_human=actual_num_human,\n",
    "        num_cav=(NUM_MERGE_0 + NUM_MERGE_1),\n",
    "        model='GRL',\n",
    "        debug=DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09014579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
