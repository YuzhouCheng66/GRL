{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a13004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yzcheng/anaconda3/envs/TorchGRL/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be saved at: GRL_Trained_Models/DD_DQN/DD_DQN_2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.5\n",
      "Training Episode: 1 Reward: -3090.2916485447035\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 2500), ('n_updates', 0), ('rlen', 2500)]\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.8\n",
      "Training Episode: 2 Reward: -1756.989819453279\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 5000), ('n_updates', 0), ('rlen', 5000)]\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.9\n",
      "Training Episode: 3 Reward: -2592.646572076917\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 7500), ('n_updates', 0), ('rlen', 7500)]\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "Training Episode: 4 Reward: -2845.299089302642\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 10000), ('n_updates', 0), ('rlen', 10000)]\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.7\n",
      "Training Episode: 5 Reward: -3273.1915600876323\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 12500), ('n_updates', 0), ('rlen', 12500)]\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.6\n",
      "Training Episode: 6 Reward: -2396.160816260951\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 15000), ('n_updates', 0), ('rlen', 15000)]\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.7\n",
      "Training Episode: 7 Reward: -2742.0974078393133\n",
      "Statistics: [('average_q', nan), ('average_loss', nan), ('cumulative_steps', 17500), ('n_updates', 0), ('rlen', 17500)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.8\n",
      "Training Episode: 8 Reward: -3784.492953160297\n",
      "Statistics: [('average_q', -0.002992923), ('average_loss', 1.3169888257980347), ('cumulative_steps', 20000), ('n_updates', 1), ('rlen', 20000)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  897\n",
      "Training Episode: 9 Reward: 5973.196315431226\n",
      "Statistics: [('average_q', -0.9831163), ('average_loss', 1.731610245257616), ('cumulative_steps', 20797), ('n_updates', 80), ('rlen', 20797)]\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Training Episode: 10 Reward: 2466.883625763133\n",
      "Statistics: [('average_q', -0.81672335), ('average_loss', 1.543299337029457), ('cumulative_steps', 23297), ('n_updates', 330), ('rlen', 23297)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1445\n",
      "Training Episode: 11 Reward: 6024.4441251622075\n",
      "Statistics: [('average_q', -0.286845), ('average_loss', 1.2283837825059891), ('cumulative_steps', 24642), ('n_updates', 465), ('rlen', 24642)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1316\n",
      "Training Episode: 12 Reward: 5377.897001482928\n",
      "Statistics: [('average_q', -0.32221645), ('average_loss', 1.1498505318164824), ('cumulative_steps', 25858), ('n_updates', 586), ('rlen', 25858)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1243\n",
      "Training Episode: 13 Reward: 5757.8923126701975\n",
      "Statistics: [('average_q', 0.177737), ('average_loss', 1.0808204048871994), ('cumulative_steps', 27001), ('n_updates', 701), ('rlen', 27001)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1468\n",
      "Training Episode: 14 Reward: 6056.210314607501\n",
      "Statistics: [('average_q', 0.32250255), ('average_loss', 1.0784809517860412), ('cumulative_steps', 28369), ('n_updates', 837), ('rlen', 28369)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1400\n",
      "Training Episode: 15 Reward: 5815.206560317542\n",
      "Statistics: [('average_q', 0.59168863), ('average_loss', 0.9749458247423172), ('cumulative_steps', 29669), ('n_updates', 967), ('rlen', 29669)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1555\n",
      "Training Episode: 16 Reward: 5914.80525410281\n",
      "Statistics: [('average_q', 0.69308144), ('average_loss', 0.965354573726654), ('cumulative_steps', 31124), ('n_updates', 1113), ('rlen', 31124)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1318\n",
      "Training Episode: 17 Reward: 5572.148331434776\n",
      "Statistics: [('average_q', 0.8903904), ('average_loss', 0.8749209451675415), ('cumulative_steps', 32342), ('n_updates', 1235), ('rlen', 32342)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  2166\n",
      "Training Episode: 18 Reward: 5995.172945659009\n",
      "Statistics: [('average_q', 0.98312426), ('average_loss', 0.7696903255581856), ('cumulative_steps', 34408), ('n_updates', 1441), ('rlen', 34408)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1113\n",
      "Training Episode: 19 Reward: 5440.879485403139\n",
      "Statistics: [('average_q', 1.0533772), ('average_loss', 0.7067866379022598), ('cumulative_steps', 35421), ('n_updates', 1543), ('rlen', 35421)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  856\n",
      "Training Episode: 20 Reward: 5454.476363057563\n",
      "Statistics: [('average_q', 1.2109774), ('average_loss', 0.6683042883872986), ('cumulative_steps', 36177), ('n_updates', 1618), ('rlen', 36177)]\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  851\n",
      "Training Episode: 21 Reward: 5603.962023691344\n",
      "Statistics: [('average_q', 1.1840246), ('average_loss', 0.6392391170561313), ('cumulative_steps', 36928), ('n_updates', 1693), ('rlen', 36928)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_4.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1225\n",
      "Training Episode: 22 Reward: 5840.033562039233\n",
      "Statistics: [('average_q', 1.2679632), ('average_loss', 0.6470597943663597), ('cumulative_steps', 38053), ('n_updates', 1806), ('rlen', 38053)]\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1920\n",
      "Training Episode: 23 Reward: 5870.313295430678\n",
      "Statistics: [('average_q', 1.5953255), ('average_loss', 0.5473746432363987), ('cumulative_steps', 39873), ('n_updates', 1988), ('rlen', 39873)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1204\n",
      "Training Episode: 24 Reward: 5020.46612007952\n",
      "Statistics: [('average_q', 1.5120528), ('average_loss', 0.5718977153301239), ('cumulative_steps', 40977), ('n_updates', 2098), ('rlen', 40977)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.9\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.7\n",
      "Training Episode: 25 Reward: 3169.958812993695\n",
      "Statistics: [('average_q', 1.4685799), ('average_loss', 0.5254433295130729), ('cumulative_steps', 43477), ('n_updates', 2348), ('rlen', 43477)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Training Episode: 26 Reward: 1611.9524148306675\n",
      "Statistics: [('average_q', 1.7351477), ('average_loss', 0.48538333833217623), ('cumulative_steps', 45977), ('n_updates', 2598), ('rlen', 45977)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.6\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.7\n",
      "satisfied:  flow_3.8\n",
      "satisfied:  flow_3.9\n",
      "Counter({'num_full_filled': 20})\n",
      "done in:  1465\n",
      "Training Episode: 27 Reward: 5814.109308358924\n",
      "Statistics: [('average_q', 1.4913057), ('average_loss', 0.4931718374788761), ('cumulative_steps', 47342), ('n_updates', 2735), ('rlen', 47342)]\n",
      "satisfied:  flow_4.0\n",
      "satisfied:  flow_4.1\n",
      "satisfied:  flow_4.2\n",
      "satisfied:  flow_4.3\n",
      "satisfied:  flow_3.0\n",
      "satisfied:  flow_4.4\n",
      "satisfied:  flow_4.5\n",
      "satisfied:  flow_4.6\n",
      "satisfied:  flow_4.7\n",
      "satisfied:  flow_3.1\n",
      "satisfied:  flow_3.2\n",
      "satisfied:  flow_3.3\n",
      "satisfied:  flow_4.8\n",
      "satisfied:  flow_3.4\n",
      "satisfied:  flow_4.9\n",
      "satisfied:  flow_3.5\n",
      "satisfied:  flow_3.6\n"
     ]
    }
   ],
   "source": [
    "from flow.core.params import VehicleParams, InFlows, SumoCarFollowingParams, SumoParams, EnvParams, InitialConfig, \\\n",
    "    NetParams, SumoLaneChangeParams, TrafficLightParams\n",
    "from flow.controllers import IDMController, RLController\n",
    "from controller import SpecificMergeRouter\n",
    "from network import HighwayRampsNetwork, ADDITIONAL_NET_PARAMS\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "# ----------- Configurations -----------#\n",
    "TRAINING = True\n",
    "# TRAINING = False\n",
    "\n",
    "# TESTING = True\n",
    "TESTING = True\n",
    "\n",
    "# DEBUG = True\n",
    "DEBUG = False\n",
    "\n",
    "RENDER = False\n",
    "# RENDER = True\n",
    "\n",
    "NUM_HUMAN = 20\n",
    "actual_num_human = 10\n",
    "\n",
    "NUM_MERGE_0 = 10\n",
    "NUM_MERGE_1 = 10\n",
    "\n",
    "MAX_AV_SPEED = 14\n",
    "MAX_HV_SPEED = 10\n",
    "\n",
    "VEH_COLORS = ['blue', 'red']\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\n",
    "Router = SpecificMergeRouter\n",
    "\n",
    "vehicles = VehicleParams()\n",
    "vehicles.add(veh_id=\"human\",\n",
    "             lane_change_params=SumoLaneChangeParams('only_strategic_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='right_of_way', min_gap=5, tau=1,\n",
    "                                                         max_speed=MAX_HV_SPEED),\n",
    "             acceleration_controller=(IDMController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             )\n",
    "\n",
    "vehicles.add(veh_id=\"merge_0\",\n",
    "             lane_change_params=SumoLaneChangeParams('no_cooperative_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='no_collide', min_gap=1, tau=1,\n",
    "                                                         max_speed=MAX_AV_SPEED),\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             color=VEH_COLORS[0])\n",
    "\n",
    "vehicles.add(veh_id=\"merge_1\",\n",
    "             lane_change_params=SumoLaneChangeParams('no_cooperative_safe'),\n",
    "             car_following_params=SumoCarFollowingParams(speed_mode='no_collide', min_gap=1, tau=1,\n",
    "                                                         max_speed=MAX_AV_SPEED),\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(Router, {}),\n",
    "             color=VEH_COLORS[1])\n",
    "\n",
    "initial_config = InitialConfig(spacing='uniform')\n",
    "\n",
    "inflow = InFlows()\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "obstacle = {\"departPos\": np.random.randint(100, 101),\n",
    "            \"arrivalPos\": 200, \n",
    "            \"arrivalEdge\":0,  \n",
    "            \"speedFactor\":0.00001, \n",
    "            \"color\":\"red\"}\n",
    "\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           period=100000,\n",
    "           depart_lane=1,\n",
    "           depart_speed=0,\n",
    "           route='routehighway_0_0',\n",
    "           number=1,\n",
    "           **obstacle)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane=0,\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=int(actual_num_human/2))\n",
    "\n",
    "inflow.add(veh_type=\"human\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane=2,\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=int(actual_num_human/2))\n",
    "\n",
    "inflow.add(veh_type=\"merge_0\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane='random',\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=NUM_MERGE_0)\n",
    "\n",
    "inflow.add(veh_type=\"merge_1\",\n",
    "           edge=\"highway_0\",\n",
    "           probability=0.1,\n",
    "           depart_lane='random',\n",
    "           depart_speed='random',\n",
    "           route='routehighway_0_0',\n",
    "           number=NUM_MERGE_1)\n",
    "\n",
    "sim_params = SumoParams(sim_step=0.1, restart_instance=True, render=RENDER, save_render=False)\n",
    "\n",
    "from specific_environment import MergeEnv\n",
    "\n",
    "intention_dic = {\"human\": 0, \"merge_0\": 1, \"merge_1\": 2}\n",
    "terminal_edges = ['off_ramp_0', 'off_ramp_1', 'highway_2']\n",
    "\n",
    "env_params = EnvParams(warmup_steps=100,\n",
    "                       additional_params={\"intention\": intention_dic,\n",
    "                                          \"max_av_speed\": MAX_AV_SPEED,\n",
    "                                          \"max_hv_speed\": MAX_HV_SPEED})\n",
    "\n",
    "additional_net_params = ADDITIONAL_NET_PARAMS.copy()\n",
    "additional_net_params['num_vehicles'] = NUM_HUMAN + NUM_MERGE_0 + NUM_MERGE_1\n",
    "additional_net_params['num_cav'] = NUM_MERGE_0 + NUM_MERGE_1\n",
    "additional_net_params['num_hv'] = NUM_HUMAN\n",
    "additional_net_params['terminal_edges'] = terminal_edges\n",
    "\n",
    "net_params = NetParams(inflows=inflow, additional_params=additional_net_params)\n",
    "\n",
    "traffic_lights = TrafficLightParams()\n",
    "\n",
    "network = HighwayRampsNetwork(\"highway_ramp\", vehicles, net_params, initial_config, traffic_lights)\n",
    "\n",
    "\n",
    "# ----------- Model Building -----------#\n",
    "flow_params = dict(\n",
    "    exp_tag='test_network',\n",
    "    env_name=MergeEnv,\n",
    "    network=network,\n",
    "    simulator='traci',\n",
    "    sim=sim_params,\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,\n",
    "    initial=initial_config,\n",
    "    tls=traffic_lights\n",
    ")\n",
    "\n",
    "# number of time steps\n",
    "flow_params['env'].horizon = 2500\n",
    "\n",
    "\n",
    "from Experiment.DuelingDoubleDQN_experiments import Experiment\n",
    "\n",
    "exp = Experiment(flow_params)\n",
    "\n",
    "\n",
    "# run the sumo simulation\n",
    "exp.run(num_runs=1, training=TRAINING,\n",
    "        testing=TESTING,\n",
    "        num_human=NUM_HUMAN,\n",
    "        actual_num_human=actual_num_human,\n",
    "        num_cav=(NUM_MERGE_0 + NUM_MERGE_1),\n",
    "        model='GRL',\n",
    "        debug=DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d73451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
